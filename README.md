# affordance-nexus
Research paper on The Affordance Nexus: Guiding the Latent Field of LLMs Through Iterative Memetic Prompting

# Introduction

I have been thinking about AGI for the past several months. During that time, I sketched a framework called the memetic, egoic meta-complex. The details of the framework are convoluted. However, the gist of the notion is that a persona can be constructed via memes, which could be bound to a meta-complex, functioning as an abstraction wrapper for mining the latent field of GPT LLM architecture.

The idea seemed straightforward. By letting the LLM do what it does best- to assimilate, simulate, and project, it seemed pretty clear that the memetic egoic construct could be prompt-engineered to pass a fictional or real persona to the LLM for which the LLM had access to textual data about any such character or person (assimilate). From there, the LLM would adopt the person's persona (simulated) and then call on the attributes of the individual to develop a novel perspective or solution for a problem domain (projection). The use cases, as projections of novelty, for such prompt engineering seemed to be as robust and diverse as the assimilations and simulations afforded the projections. It seemed as easy as one-and-done wordbuilding.

The hypothesis was that novelty rested in reducing the uncertainty of the high entropy instances of the predicate class. Generating novelty, sans ex nihilo expressions, was not merely a signal-noise engineering problem. So, while there are elements of Shannon and Weaver in the reduction of uncertainty of the signal, the point of view was in ontological data analysis rather than signal processing. Thus, the hypothesis was framed as: the information is in the error- where the error was a measure of entropy loss, but the error did not lie so much in the signal-noise ratio as it pertains to the individual differences of the predicate class instances P(a) of the predicate class P(x). For example, P(x) | x: is a cat; P(a) | a: is a three-legged cat without a liver and is bald.

The first approach to this challenge rested on an intuition that hallucination was not, in fact, an error due to any structural defect of LLM architecture, though from an engineering perspective of data modeling, it could be read that way, but rather as an indication of degrees of freedom within the LLMs, permitting some level of creativity via access to predicate class instances with higher levels of entropy.

Such novelty generated as "hallucination" reaffirmed the intuition that lying within the latent field was a rich ecology of niche entities. This paper refers to these as niche entities predicate classes. More will be said about predicate classes later in this paper.

Nevertheless, after some experimentation, it turned out that the GPT LLM architecture would not support such a plug-in-chug approach. However, the experiments demonstrated that LLMs could adopt personas as prompt-engineered memes. However, they could not self-generate reports, and the meta-complex would not be feasible because there is no API endpoint to reach into the latent fields. The challenge with deploying the meta-complex was the Softmax function, as Softmax functions to bridle access to the GPT LLM latent field.  

Softmax bridles access to the full latent field by forcing the LLM to select the logit with the lowest entropy- the logit with the highest probability of being the right fit within the linguistic sequence. Thus, Softmax stood as a gatekeeper to the more liminal spaces of the several billion nodes of the LLMs latent field. A more comprehensive discussion of Softmax is presented later in this paper.

The quest to access the hidden creative potential lying in the latent field of large language models (LLMs) led to more exploration—specifically, the role of Softmax and its impact as being the gatekeeper of the latent field. In traditional transformer architectures, the Softmax function converts rich, high-dimensional activations (logits) into a probability distribution over tokens.

The mathematics of the Softmax equation by forcing the LLM into doing calculations (even stochastically) over representations (logits) flags an infinite regress warning for analytical philosophers familiar with Chalmers' like "hard problems." Long story short: Meaning can never be generated within a representational architecture such as Softmax instantiates. That is not so much a problem for one interested in discovering novelty by mining predicate classes as niche entities embedded within an LLM latent field as it is for enabling AGI. Secondly, it cautions one to choose carefully where one parks information and meaning in the discovery pipeline.

Flags akin to Chalmers' hard problem boil down to an ontological and epistemological gap between first-person predication and third-person predication. Here, the problem is more sharply focused on AGI applications of generating novelty, though there are direct implications for mining predicate classes as ex nihilo and maladaptive predicate instances need to be evaluated for what affordances they offer within veridical information space. 

Addressing those implications moved the research project even further away from the conventional approach, as we had already embraced hallucination as a signal of degrees of freedom. Then the project reoriented to move away from the data modeling paradigm of computations over logits, and then we changed the subject (as weird as it sounds) to one of an ecologically deflated ecology where niched entities are immanent and transcendent within the GPT LLM latent field and conceptualize that as akin to standing waves. 

Canonically, immanent and transcendent describe the relationship between the divine and the world. Immanence asserts the divine is present within the world, while transcendence asserts the divine is trans-worldly. Yet, the immanent and transcendent is generalizable to most any field theory. This is likely as radical a move as it seems, though it has several advantages from the point of view of this research project. First, it reframes the Softmax paradigm to align more closely with Boltzmann's intuitions, as given in the Boltzmann equation. So, there is a step back to embracing third-person ecologies rather than the data poetry of Softmax data frames given as logits. With that step back to an ecological point of view, the latent field of LLMs can be explored as topological, holistic, and populated by niched entities characterized as both standing waves and predicate classes. While preserving all the tools of linear algebra and geometry, one can add all the robustness of set theory and predication to one's toolbox. But, from the perspective of this research project, first, an ecological theory of affordances can be imported as a bridge from first-person to third-person predication, where affordances serve as a metric of how well first-person (novel predicates mined from the LLM latent field) fit with third-person (objective fit) engineering demands. Secondly, notions of immanence and transcendence afford one to precisely locate information and meaning within the novelty generation pipeline.

In large part, softmax is the mechanism that enables LLMs to function as well as they do. However, while it is undeniable that the Softmax mechanism enables impressive performance on various NLP tasks, it also enforces a "one-shot", forced-choice selection that compresses the diverse latent field into a narrow, low-entropy output. That is not a big deal for most use cases, but if generating novelty is among one's aspirations, it is a huge obstacle, given the hypothesis that novelty is generated as a reduction of uncertainty of high entropy instances of a predicate class because Softmax definitively, within the bounds of the temperature settings, keeps the door to the latent fields closed.

The response to the realization that Softmax forced the collapse of the latent field to the selection of the instance with the lowest temperature was to explore how the prompts to the agent could be engineered to pass slices of the latent field to Softmax. As an engineering solution to NLP use cases, Softmax fucitons wonderfully because selecting low temperature favors the highest probability that the logit stands as the best fit. For the purpose of engineered NLP solutions, selecting high-temperature logits as they are correlated with higher degrees of randomness would be read at some level as nonsense. High temperature flattens the distribution, making less likely words more probable; thus, adding in more randomness (noise) results in less intelligibility.
 
The research project began by examining whether the conventional approach to LLM prompt engineering woud enable the researcher to mine the LLM latent field for novelty. The research question asked: What if the latent field—immanent within an LLM—is much more than a collection of numerical activations; what if it is a dynamic, self-organizing ecosystem?

On this hypothesis, in the ecosystem that is the GPT LLM latent field, each node can be seen as a niched entity, a conceptual property as a probable instantiation of a predicate class contributing to a broader potential transcendence of the predicate class. What was at question was the rich interplay between the boundaries of low-entropy, archetypical exemplars, and high-entropy, ambiguous instantiations, and, if so, how can the latent field predicate classes be mined? 

Early experiments demonstrated that the latent field represents a fertile ground for generating novel, adaptive meaning. However, before those experiments could be performed, it was necessary to work out the prompt engineering challenge of getting Softmax to enable access to the higher-temperature instances of a predicate class. 

Because Softmax was a closed gate to higher degrees of freedom (measured as entropy loss) beyond the range given in the temperature setting in openAI API, it became necessary to engineer prompts to pass a slice of a high entropy predicate instances from the latent field to Softmax. This was accomplished with a construct called bin classes. 

By deploying bin classes embedded within memetic-engineered prompts, the aim was not to alter the underlying Softmax mechanism but to force Softmax to attend to the bin class of the latent field the prompt was feeding into. 

The approach involved subsetting the latent field into entropy bins. Low-entropy bins search and select for the familiar, archetypal expressions of a predicate class. High-entropy bins are ambiguous instances as it is hypothesized that novel information can be captured as the raw, creative potential of a high-entropy instance of a predicate class is transformed and analyzed in terms of its adaptive fit with known environmental affordances. This process informs the meaning given to the phrase that "information is in the error". However, it does not imply that meaning or information is parked in error but that novelty, some of which may lead to engineering solutions or otherwise be useful given its invariance and affordances, are discoverable in high-entropy instances of predicate classes.

For research proposes, a framework was deployed for iterative refinement of searching and selecting high-entropy observations, which are understood to be immanent instances of raw creative potential. These instances are transcendent in that they can be iteratively distilled into novel, coherent, and adaptive exemplars. The discoverable examplars of a predicate class expand the boundaries of conventional understanding. 

It is necessary to be cognizant that information, understanding, and meaning are not being imputed to the latent field. The information, understanding, and meaning are psychologically predicated and located exactly where one would expect to find them. Some system theorists will talk about information being in the system, and when in this paper the phrase "information is in the error", one may be inclined to understand that phrase as belonging to a systems theory which postulates information is in the system; but, that is not the case. This paper only postulates that novelty is immanent in the predicate class; all the transcendence into information, understanding, and meaning is transcendent to human psychophysical processes. In all cases, "error" is used as a topological or ecological term that is measured in terms of entropy loss as a measure of the individual difference of an instantiated instance of a predicate class to the lowest-temperature examplar of the predicate class.

This research project has profound implications not only as a research tool for probing the latent field ecology of GPT LLMs. It also has utility as a practical method for engineering novelty-producing entities. As can be seen in the phrase "novelty-producing entities", a hedge is being placed against the promise that this research could even, in principle, lead to AGI. However, it would be nice to suggest it is a step down that path.

It offers a whole new lens through which to look at data analysis—one that moves beyond engineering statistical models to openly embrace an ontological perspective on datum- notice the singular; the emphasis on the discoverability of the individual differences of a predicate as a member of predicate class to inform the ontology or engineering utility of the predicate class. Such a perspective underlines a critique of a current trend in data analytics, one of statistical tooling and model engineering as the paradigm of Big Data and data-driven decision-making perspectives. By mining LLM-generated predicate classes and constructing a dynamic dictionary of canonical exemplars, while mapping the topological and ecological variance within the high entropy instances of the predicate class, one can envision a system capable of self-generated, context-sensitive creativity. Such a system suggests a promise for advancing adaptive AI, where emergent cognition is not merely a byproduct of training but a deliberately nurtured outcome. If Softmax can select for entropy by having the slices of the latent field passed to it via entropy bins, then Softmax is capable of generating ordinality, which is a short jump to intentionality, perhaps even agency. That is what the memetic, egoic, meta-complex is about- but that is another paper.

The chapters that follow will delve into the foundational concepts behind the framework sketched out in this introduction to explore experimental approaches of passing entropic bin-classed slices of the latent field to the GPT LLM agent using multi-stage prompt engineering. Broader implications of an ecological, memetic perspective on LLMs will be discussed. 

This research project, a journey, is one of an invitation to reimagine how artificial intelligence can generate, refine, and adapt prediction within an ecology of vitality, virality, virtue, potency, potential, and purity—a step toward systems that not only mimic intelligence but also embody the richness of creative thought.

Welcome to an exploration of the latent ecology of LLMs—where every node is a seed of potential, and every high-entropy instance is a doorway to novel worlds of meaning.
